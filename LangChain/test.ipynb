{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81ea2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-respectful-bank-15\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"fffda107fc0774dad693d83be19aa5b3.5FYbdewtAJF1K471\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://open.bigmodel.cn/api/paas/v4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4db3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello ðŸ‘‹! I'm ChatGLMï¼ˆæ™ºè°±æ¸…è¨€ï¼‰, the artificial intelligence assistant, nice to meet you. Feel free to ask me any questions.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 11, 'total_tokens': 47, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '20250620170537843ac012ff5e413e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c2cd95ac-911a-4878-830f-e42a717e9fc6-0', usage_metadata={'input_tokens': 11, 'output_tokens': 36, 'total_tokens': 47, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"GLM-4-Flash-250414\", temperature=0)\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat_model = ChatOllama(\n",
    "    model = \"gemma3:4b\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # base_url= \"http://192.168.23.99:11434\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266bf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"GLM-4-Flash-250414\",\n",
    "    openai_api_key=\"fffda107fc0774dad693d83be19aa5b3.5FYbdewtAJF1K471\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71543bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, here's one for you:\\n\\nWhy don't bears play cards in the forest?\\n\\nBecause there are too many cheetahs!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 14, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '20250618155529e8a85a65cc114506', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--0e08959b-e326-4fc2-96b4-3cb8471825fd-0', usage_metadata={'input_tokens': 14, 'output_tokens': 30, 'total_tokens': 44, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Tell me a joke about bears!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e2a9725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, here you go:\\n\\nWhy don\\'t bears get sunburned?\\n\\n... Because they have too much fur!\\n\\n**(Alternatively, maybe a bit darker humor):**\\n\\nHow do you know if a bear has been in your fridge?\\n\\n... You\\'ll find your empty wallet and a note saying, \"Don\\'t worry, I only took the groceries!\"\\n\\nHope that gave you a chuckle!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 14, 'total_tokens': 93, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '202506181555346e187da3e03c4bc1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c510c96d-9586-42b0-b05b-947248320fa6-0', usage_metadata={'input_tokens': 14, 'output_tokens': 79, 'total_tokens': 93, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_model.invoke([\n",
    "    HumanMessage(\"Tell me a joke about bears!\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e4b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "joke_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class comedian.\"),\n",
    "    (\"human\", \"Tell me a joke about {topic}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4d515e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class comedian.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about beets', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_prompt.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4434455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = joke_prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6bac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Alright, alright, settle down, fur balls! Okay, so my dog, Barnaby... he\\'s got this habit. Every time I say \"Barnaby, come here!\", he doesn\\'t come. He just runs the other way. I asked him why, and he just looks at me with those big, soulful eyes and says, \"Boss, ain\\'t nobody got time for that sh**!\" Classic Barnaby.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 20, 'total_tokens': 109, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '20250618155542e2bd55c55cf84154', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f2dc79ec-9881-4f7d-9917-d10b502c5845-0', usage_metadata={'input_tokens': 20, 'output_tokens': 89, 'total_tokens': 109, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains.invoke({\"topic\": \"dogs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e02a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "str_chain = chains | StrOutputParser()\n",
    "\n",
    "# Equivalent to:\n",
    "# str_chain = joke_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ec6669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, alright, settle down folks, this one's for the green thumbs in the audience!\n",
      "\n",
      "So, I asked my plant therapist about trees.\n",
      "\n",
      "She said, \"They're great. They're very rooted, very grounded. And they really help you branch out and explore your inner thoughts.\"\n",
      "\n",
      "I just looked at her and said, \"Sounds nice, but can we focus on my inability to remember where I put my keys? That's my main issue.\"\n",
      "\n",
      "So, trees are fine. But honestly, my main relationship with trees is when I'm trying to park my car. \"Is there a spot *over there*?\" Yeah, right. Like that tree is just gonna move!\n"
     ]
    }
   ],
   "source": [
    "print(str_chain.invoke({\"topic\": \"æ ‘æœ¨\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47dd4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, alright, settle down folks, you're a beautiful crowd. You know, when I was younger, I thought beets were just... interesting.\n",
      "\n",
      "Then I got older, and discovered their potential. Now I see beets everywhere!\n",
      "\n",
      "Want to know why?\n",
      "\n",
      "Because they're **beet**-oming!\n",
      "\n",
      "*(Pauses for effect)*\n",
      "\n",
      "...Okay, okay, bad pun. See? I told you I was a *world class* comedian! Give me another minute..."
     ]
    }
   ],
   "source": [
    "for chunk in str_chain.stream({\"topic\": \"beets\"}):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45e7d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm an AI, so I don't have real-time access to your current location or the current time in your timezone.\\n\\nHowever, you can easily find out the current time by:\\n\\n1.  Checking the clock or watch on your device.\\n2.  Visiting a website that displays the current time (like timeanddate.com).\\n3.  Checking the time in your device's settings.\\n\\nIf you tell me your location or timezone, I can give you the time in that specific place!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 13, 'total_tokens': 115, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '20250618155603e1b9e0a05fb44232', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--0df2c002-7b1e-4dd4-9178-216d48a399da-0', usage_metadata={'input_tokens': 13, 'output_tokens': 102, 'total_tokens': 115, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"what it the current time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e167d562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current date is **2025-06-18**.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that the current date is \"{current_date}\".'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acb44ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The Old Ship Saloon's total revenue in Q1 2023 was $1,470,000.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 24, 'total_tokens': 49, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'GLM-4-Flash-250414', 'system_fingerprint': None, 'id': '20250618155610dcd1a68d8fd44d66', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5a0827b7-8490-4eb7-935f-8cb3cd2c6b05-0', usage_metadata={'input_tokens': 24, 'output_tokens': 25, 'total_tokens': 49, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\n",
    "    \"What was the Old Ship Saloon's total revenue in Q1 2023?\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19f2d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Old Ship Saloon's total revenue in Q1 2023 was $174,782.38.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE = \"\"\"\n",
    "Old Ship Saloon 2023 quarterly revenue numbers:\n",
    "Q1: $174782.38\n",
    "Q2: $467372.38\n",
    "Q3: $474773.38\n",
    "Q4: $389289.23\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You are a helpful assistant. Use the following context when responding:\\n\\n{context}.'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = rag_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "rag_chain.invoke({\n",
    "    \"question\": \"What was the Old Ship Saloon's total revenue in Q1 2023?\",\n",
    "    \"context\": SOURCE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c357d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You know that the current date is \\\"2025-06-18\\\".\\nHuman: What is the current date?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The current date is June 18, 2025.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The current date is June 18, 2025.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 28,\n",
      "                \"total_tokens\": 42,\n",
      "                \"completion_tokens_details\": null,\n",
      "                \"prompt_tokens_details\": null\n",
      "              },\n",
      "              \"model_name\": \"GLM-4-Flash-250414\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"20250618155622056d6f2284344aaf\",\n",
      "              \"service_tier\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--b5bc7495-af42-4ba8-909f-aadcd5fffc67-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 28,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 42,\n",
      "              \"input_token_details\": {},\n",
      "              \"output_token_details\": {}\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 28,\n",
      "      \"total_tokens\": 42,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"prompt_tokens_details\": null\n",
      "    },\n",
      "    \"model_name\": \"GLM-4-Flash-250414\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"20250618155622056d6f2284344aaf\",\n",
      "    \"service_tier\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The current date is June 18, 2025.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.64s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The current date is June 18, 2025.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current date is June 18, 2025.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that the current date is \"{current_date}\".'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b944ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'name': 'RunnableSequence', 'tags': [], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 6, 18)}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_prompt_start', 'name': 'ChatPromptTemplate', 'run_id': 'fca31148-406a-4b10-bb2a-6440dc2d6144', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 6, 18)}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_prompt_end', 'name': 'ChatPromptTemplate', 'run_id': 'fca31148-406a-4b10-bb2a-6440dc2d6144', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 6, 18)}, 'output': ChatPromptValue(messages=[SystemMessage(content='You know that the current date is \"2025-06-18\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the current date?', additional_kwargs={}, response_metadata={})])}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_start', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'input': {'messages': [[SystemMessage(content='You know that the current date is \"2025-06-18\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the current date?', additional_kwargs={}, response_metadata={})]]}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_start', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': 'The'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': 'The'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' is'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' is'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' June', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' June'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' June'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='18', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '18'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '18'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '5'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '5'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-flash-250414'}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde', usage_metadata={'input_tokens': 28, 'output_tokens': 14, 'total_tokens': 42, 'input_token_details': {}, 'output_token_details': {}})}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_end', 'name': 'ChatOpenAI', 'run_id': 'd65bf3df-4d44-43c1-8571-9764a1fdffde', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'GLM-4-Flash-250414', 'ls_model_type': 'chat', 'ls_temperature': 0.95}, 'data': {'input': {'messages': [[SystemMessage(content='You know that the current date is \"2025-06-18\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the current date?', additional_kwargs={}, response_metadata={})]]}, 'output': {'generations': [[{'text': 'The current date is June 18, 2025.', 'generation_info': {'finish_reason': 'stop', 'model_name': 'glm-4-flash-250414'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content='The current date is June 18, 2025.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-flash-250414'}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde', usage_metadata={'input_tokens': 28, 'output_tokens': 14, 'total_tokens': 42, 'input_token_details': {}, 'output_token_details': {}})}]], 'llm_output': None, 'run': None, 'type': 'LLMResult'}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_end', 'name': 'StrOutputParser', 'run_id': '640823aa-786b-4c30-9a4f-2afe48b34cd7', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'input': AIMessageChunk(content='The current date is June 18, 2025.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-flash-250414'}, id='run--d65bf3df-4d44-43c1-8571-9764a1fdffde', usage_metadata={'input_tokens': 28, 'output_tokens': 14, 'total_tokens': 42, 'input_token_details': {}, 'output_token_details': {}}), 'output': 'The current date is June 18, 2025.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_end', 'name': 'RunnableSequence', 'run_id': '69e99c17-58e8-4e2c-99bb-80a95d9ec307', 'tags': [], 'metadata': {}, 'data': {'output': 'The current date is June 18, 2025.'}, 'parent_ids': []}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Turn off debug mode for clarity\n",
    "set_debug(False)\n",
    "\n",
    "stream = chain.astream_events({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "}, version=\"v1\")\n",
    "\n",
    "async for event in stream:\n",
    "    print(event)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36bc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
